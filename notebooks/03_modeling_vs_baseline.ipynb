{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ff8bc5b-980b-4c08-ab1c-e21755551973",
   "metadata": {},
   "source": [
    "# Modeling vs. Baseline Comparison\n",
    "\n",
    "The goal of this notebook is to evaluate whether machine learning models provide meaningful improvements over simple, well-designed baselines for weekly sales forecasting. Rather than immediately optimizing a complex model, this notebook focuses on understanding how much predictive signal is already captured by historical sales patterns.\n",
    "\n",
    "Several baseline approaches are constructed using lagged sales features, including short-term momentum and yearly seasonality. These baselines are then compared against an initial machine learning model using a time-based validation split. This comparison helps determine whether additional model complexity is justified and identifies the primary drivers of sales behavior in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c34d21fc-1372-4f39-8d3b-bb5ffb35eb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_lag_1</th>\n",
       "      <th>sales_lag_2</th>\n",
       "      <th>sales_roll_4</th>\n",
       "      <th>Year</th>\n",
       "      <th>Holiday_Lead</th>\n",
       "      <th>Holiday_Lag</th>\n",
       "      <th>Sin_Month</th>\n",
       "      <th>Cos_Month</th>\n",
       "      <th>Sin_Week</th>\n",
       "      <th>Cos_Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.568065</td>\n",
       "      <td>0.822984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>46039.49</td>\n",
       "      <td>1</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>0.748511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>41595.55</td>\n",
       "      <td>0</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>46039.49</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.663123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>19403.54</td>\n",
       "      <td>0</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>41595.55</td>\n",
       "      <td>46039.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.822984</td>\n",
       "      <td>0.568065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>21827.90</td>\n",
       "      <td>0</td>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>19403.54</td>\n",
       "      <td>41595.55</td>\n",
       "      <td>32990.77</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.464723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Dept       Date  Weekly_Sales  IsHoliday  Temperature  Fuel_Price  \\\n",
       "0      1     1 2010-02-05      24924.50          0        42.31       2.572   \n",
       "1      1     1 2010-02-12      46039.49          1        38.51       2.548   \n",
       "2      1     1 2010-02-19      41595.55          0        39.93       2.514   \n",
       "3      1     1 2010-02-26      19403.54          0        46.63       2.561   \n",
       "4      1     1 2010-03-05      21827.90          0        46.50       2.625   \n",
       "\n",
       "   MarkDown1  MarkDown2  MarkDown3  ...  sales_lag_1  sales_lag_2  \\\n",
       "0        NaN        NaN        NaN  ...          NaN          NaN   \n",
       "1        NaN        NaN        NaN  ...     24924.50          NaN   \n",
       "2        NaN        NaN        NaN  ...     46039.49     24924.50   \n",
       "3        NaN        NaN        NaN  ...     41595.55     46039.49   \n",
       "4        NaN        NaN        NaN  ...     19403.54     41595.55   \n",
       "\n",
       "   sales_roll_4  Year Holiday_Lead  Holiday_Lag  Sin_Month     Cos_Month  \\\n",
       "0           NaN  2010            1            0   0.866025  5.000000e-01   \n",
       "1           NaN  2010            0            0   0.866025  5.000000e-01   \n",
       "2           NaN  2010            0            1   0.866025  5.000000e-01   \n",
       "3           NaN  2010            0            0   0.866025  5.000000e-01   \n",
       "4      32990.77  2010            0            0   1.000000  6.123234e-17   \n",
       "\n",
       "   Sin_Week  Cos_Week  \n",
       "0  0.568065  0.822984  \n",
       "1  0.663123  0.748511  \n",
       "2  0.748511  0.663123  \n",
       "3  0.822984  0.568065  \n",
       "4  0.885456  0.464723  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "\n",
    "train_df = pd.read_csv(\"../data/interim/model_features.csv\", parse_dates=[\"Date\"])\n",
    "train_df = train_df.sort_values([\"Store\",\"Dept\",\"Date\"]).reset_index(drop=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a38884b-4d18-4597-87de-6e6774bb1c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start building markdown missingness indicators using only dates after markdown rollout (based on EDA)\n",
    "markdown_cols = [\"MarkDown1\",\"MarkDown2\",\"MarkDown3\",\"MarkDown4\",\"MarkDown5\"]\n",
    "\n",
    "md_start_date = train_df.loc[\n",
    "    train_df[markdown_cols].notna().any(axis=1), \"Date\"\n",
    "].min()\n",
    "\n",
    "\n",
    "cutoff_date = pd.Timestamp(\"2012-02-01\")  \n",
    "\n",
    "md_era = train_df[(train_df[\"Date\"] >= md_start_date) & (train_df[\"Date\"] < cutoff_date)].copy()\n",
    "\n",
    "# store-week level presence: any dept non-null counts as \"available\"\n",
    "store_week_md = (\n",
    "    md_era.groupby([\"Store\",\"Date\"])[markdown_cols]\n",
    "    .apply(lambda g: g.notna().any())\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "md_availability = (\n",
    "    store_week_md.groupby(\"Store\")[markdown_cols]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "#build availabity columns and merge\n",
    "md_availability.columns = [\"Store\"] + [f\"{c}_avail_rate\" for c in markdown_cols]\n",
    "\n",
    "train_df = train_df.merge(md_availability, on=\"Store\", how=\"left\")\n",
    "\n",
    "avail_cols = [f\"{c}_avail_rate\" for c in markdown_cols]\n",
    "train_df[avail_cols] = train_df[avail_cols].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee29f01-91ae-4269-a031-2a8b7b537818",
   "metadata": {},
   "source": [
    "## Markdown Availability Feature Construction\n",
    "\n",
    "Markdown data is sparse and inconsistently reported across departments. To handle this, markdown availability is defined at the store–week level: if any department in a store reports a markdown in a given week, that markdown is treated as available for the store that week.\n",
    "\n",
    "Availability rates are then computed per store and merged back into the training data. This approach preserves information about promotional coverage while avoiding misleading zeros caused by missing or unreported markdown values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13cfb31c-12f7-46ef-b27c-e5627788d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build presence indicators based on EDA\n",
    "for c in markdown_cols:\n",
    "    train_df[f\"{c}_present\"] = train_df[c].notna().astype(int)\n",
    "\n",
    "train_df[markdown_cols] = train_df[markdown_cols].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4acee0f8-b477-4648-a366-317cf2eaf3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets build a new 52 week lag feature to use in new weighted baseline based on first model run to beat\n",
    "train_df = train_df.sort_values([\"Store\", \"Dept\", \"Date\"])\n",
    "\n",
    "train_df[\"sales_lag_52\"] = (\n",
    "    train_df.groupby([\"Store\", \"Dept\"])[\"Weekly_Sales\"]\n",
    "            .shift(52)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "356edb2f-6bea-4a10-b907-24bab9908c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define time based split using cutoff point \n",
    "cutoff_date = pd.Timestamp(\"2012-02-01\")\n",
    "\n",
    "train = train_df[train_df[\"Date\"] < cutoff_date].copy()\n",
    "val   = train_df[train_df[\"Date\"] >= cutoff_date].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "836b7247-ad95-4c77-bfb9-ff31f18c6d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nulls only in training set\n",
    "lag_cols = [\"sales_lag_1\",\"sales_lag_2\",\"sales_roll_4\"]\n",
    "train_clean = train[train[\"Date\"] < cutoff_date].dropna(subset=lag_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "637d7253-0285-4dfb-974e-cb090d902885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1676.1818784559068"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find baseline MAE using last week sales (assuming last weeks sales will be next week sales\n",
    "val_base = val.copy()\n",
    "val_base[\"y_pred_naive\"] = val_base[\"sales_lag_1\"]\n",
    "\n",
    "mask = val_base[\"y_pred_naive\"].notna()\n",
    "\n",
    "mae_naive = mean_absolute_error(\n",
    "    val_base.loc[mask,\"Weekly_Sales\"],\n",
    "    val_base.loc[mask,\"y_pred_naive\"]\n",
    ")\n",
    "\n",
    "mae_naive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2735aae-f5e3-4208-b639-cb8974ad9794",
   "metadata": {},
   "source": [
    "## Seasonal Lag Baseline Construction\n",
    "\n",
    "To capture strong yearly seasonality observed in the data, a 52-week lag feature is constructed at the store–department level. This feature represents sales from the same week in the prior year and is used to build a stronger baseline model.\n",
    "\n",
    "A time-based split is then applied to separate training and validation periods. Baseline performance is evaluated using simple lagged sales assumptions before comparing against more complex models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27858c58-c414-44ec-b00a-0b46f1f37975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1517.2076850574074"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build a rfr to compare to baseline model \n",
    "feature_cols = [\n",
    "    \"sales_lag_1\",\"sales_lag_2\",\"sales_roll_4\",\n",
    "    \"Sin_Week\",\"Cos_Week\",\"Sin_Month\",\"Cos_Month\",\"Year\",\n",
    "    \"IsHoliday\",\"Holiday_Lag\",\"Holiday_Lead\",\n",
    "    \"Temperature\",\"Fuel_Price\",\"CPI\",\"Unemployment\",\n",
    "    \"Size\",\"Store\",\"Dept\",\"Type\",\n",
    "    \"MarkDown1\",\"MarkDown2\",\"MarkDown3\",\"MarkDown4\",\"MarkDown5\",\n",
    "    \"MarkDown1_present\",\"MarkDown2_present\",\"MarkDown3_present\",\"MarkDown4_present\",\"MarkDown5_present\",\n",
    "    \"MarkDown1_avail_rate\",\"MarkDown2_avail_rate\",\"MarkDown3_avail_rate\",\"MarkDown4_avail_rate\",\"MarkDown5_avail_rate\"\n",
    "]\n",
    "\n",
    "#split features by dtype for preprocessing\n",
    "categorical = [\"Store\",\"Dept\",\"Type\"]\n",
    "numeric = [c for c in feature_cols if c not in categorical]\n",
    "\n",
    "X_train = train_clean[feature_cols]\n",
    "y_train = train_clean[\"Weekly_Sales\"]\n",
    "X_val = val[feature_cols]\n",
    "y_val = val[\"Weekly_Sales\"]\n",
    "\n",
    "#this will become more intricate when we build a final model\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", SimpleImputer(strategy=\"median\"), numeric),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
    "])\n",
    "\n",
    "#just pick standard hyperparameters for now will do grid search later\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=12,\n",
    "    min_samples_leaf=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "#fit to pipeline\n",
    "model = Pipeline([(\"prep\", preprocess), (\"rf\", rf)])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "mean_absolute_error(y_val, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "624bae85-1330-4f1d-b319-ce5d58a9adc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1474.8523001528415"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets evaluate a stronger weighted baseline to beat that takes into account 52 week lag and 1 week lag\n",
    "null_mask = val[\"sales_lag_1\"].notna() & val[\"sales_lag_52\"].notna()\n",
    "\n",
    "hybrid_pred = (\n",
    "    0.7 * val.loc[null_mask, \"sales_lag_1\"] +\n",
    "    0.3 * val.loc[null_mask, \"sales_lag_52\"]\n",
    ")\n",
    "\n",
    "mae_hybrid = mean_absolute_error(\n",
    "    val.loc[null_mask, \"Weekly_Sales\"],\n",
    "    hybrid_pred\n",
    ")\n",
    "\n",
    "mae_hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c758b07a-de72-45b8-acba-116f69407f94",
   "metadata": {},
   "source": [
    "## Baseline vs Model Performance\n",
    "\n",
    "I evaluated a stronger baseline that combines recent sales (lag-1) and yearly seasonality (lag-52).  \n",
    "This simple hybrid baseline outperformed the Random Forest model on MAE.\n",
    "\n",
    "This result suggests that most of the predictable signal in weekly sales is driven by temporal\n",
    "patterns, especially short-term momentum and annual seasonality. Additional features such as\n",
    "markdowns, holidays, and macro variables provided limited incremental improvement beyond these\n",
    "lags.\n",
    "\n",
    "This is a common outcome in retail demand forecasting and highlights the importance of using\n",
    "strong baselines when evaluating more complex models.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
